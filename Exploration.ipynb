{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "import cv2\n",
    "import glob\n",
    "import tensorflow as tf\n",
    "import tensorflow.contrib.eager as tfe\n",
    "\n",
    "tfe.enable_eager_execution()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "images=[]\n",
    "for file in glob.glob(\"./Train/CameraRGB/*.png\"):\n",
    "    img = cv2.imread(file)\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    images.append(img)\n",
    "\n",
    "masks = []\n",
    "for file in glob.glob(\"./Train/CameraSeg/*.png\"):\n",
    "    img = cv2.imread(file)\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    masks.append(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def multi_plot(images):\n",
    "    plt.figure(figsize=(20,20))\n",
    "    count = len(images)\n",
    "    \n",
    "    for i in range(count):\n",
    "        plt.subplot(1, count, i+1)\n",
    "        plt.imshow(images[i])\n",
    "\n",
    "multi_plot([images[0], images[1], images[2], images[3][:, :, 1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def preprocess_labels(label_image):\n",
    "    road = np.zeros_like(label_image[:, :, 0])\n",
    "    lane_marking_pixels = (label_image[:,:,0] == 6).nonzero()\n",
    "    road_pixels = (label_image[:,:,0] == 7).nonzero()\n",
    "    road[lane_marking_pixels] = 1\n",
    "    road[road_pixels] = 1\n",
    "\n",
    "    car = np.zeros_like(road)\n",
    "    vehicle_pixels = (label_image[:,:,0] == 10).nonzero()\n",
    "    # Isolate vehicle pixels associated with the hood (y-position > 496)\n",
    "    hood_indices = (vehicle_pixels[0] >= 496).nonzero()[0]\n",
    "    hood_pixels = (vehicle_pixels[0][hood_indices], \\\n",
    "                   vehicle_pixels[1][hood_indices])\n",
    "    car[vehicle_pixels] = 1\n",
    "    car[hood_pixels] = 0\n",
    "    return np.stack([road, car], axis=2)\n",
    "\n",
    "# new_label = preprocess_labels(masks[1])\n",
    "# print(new_label[:, :, 0].shape)\n",
    "# plt.imshow(new_label[:, :, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_masks = [preprocess_labels(mask) for mask in masks]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index in range(15, 20):\n",
    "    multi_plot([images[index], processed_masks[index][:, :, 0], processed_masks[index][:, :, 1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DownSample(tf.keras.Model):\n",
    "    def __init__(self, filters):\n",
    "        super(DownSample, self).__init__()\n",
    "        self.conv = tf.keras.layers.Conv2D(filters, kernel_size=(3, 3), padding='same', strides=(2, 2))\n",
    "        self.prelu = tf.keras.layers.PReLU()\n",
    "        self.maxpool = tf.keras.layers.MaxPooling2D(pool_size=(2, 2), padding='same')\n",
    "        self.concat = tf.keras.layers.Concatenate()\n",
    "        \n",
    "    def call(self, inputs):\n",
    "        pool = self.maxpool(inputs)\n",
    "        x = self.conv(inputs)\n",
    "        x = self.prelu(x)\n",
    "        x = self.concat([x, pool])\n",
    "        return x\n",
    "    \n",
    "model = DownSample(filters=13)\n",
    "batch = tf.random_normal((1, 600, 800, 3))\n",
    "%time out = model(batch)\n",
    "\n",
    "print(out.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DilationLayer(tf.keras.Model):\n",
    "    def __init__(self, filters):\n",
    "        super(DilationLayer, self).__init__()\n",
    "        self.conv1 = tf.keras.layers.Conv2D(filters, kernel_size=(1, 1), padding='same', dilation_rate=(1,1))\n",
    "        self.prelu1 = tf.keras.layers.PReLU()\n",
    "        self.conv2 = tf.keras.layers.Conv2D(filters, kernel_size=(3, 3), padding='same', dilation_rate=(2,2))\n",
    "        self.prelu2 = tf.keras.layers.PReLU()\n",
    "        self.batchnorm = tf.keras.layers.BatchNormalization()\n",
    "        \n",
    "    def call(self, inputs):\n",
    "        x = self.conv1(inputs)\n",
    "        x = self.prelu1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.prelu2(x)\n",
    "        x = self.batchnorm(x)\n",
    "        return x\n",
    "    \n",
    "model = DilationLayer(filters=13)\n",
    "batch = tf.random_normal((1, 75, 100, 25))\n",
    "%time out = model(batch)\n",
    "\n",
    "print(out.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class UpSample(tf.keras.Model):\n",
    "    def __init__(self, filters):\n",
    "        super(UpSample, self).__init__()\n",
    "        self.conv1 = tf.keras.layers.Conv2DTranspose(filters, kernel_size=(3, 3), strides=(2,2), padding='same')\n",
    "        self.prelu1 = tf.keras.layers.PReLU()\n",
    "        self.conv2 = tf.keras.layers.Conv2D(filters, kernel_size=(3, 3), padding='same', dilation_rate=(1,1))\n",
    "        self.prelu2 = tf.keras.layers.PReLU()\n",
    "        \n",
    "    def call(self, inputs):\n",
    "        x = self.conv1(inputs)\n",
    "        x = self.prelu1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.prelu2(x)\n",
    "        return x\n",
    "    \n",
    "model = UpSample(filters=13)\n",
    "batch = tf.random_normal((1, 75, 100, 25))\n",
    "%time out = model(batch)\n",
    "\n",
    "print(out.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "class DilatedCNN(tf.keras.Model):\n",
    "    def __init__(self):\n",
    "        super(DilatedCNN, self).__init__()\n",
    "        self.down1 = DownSample(filters=13)\n",
    "        self.down2 = DownSample(filters=24)\n",
    "        self.down3 = DownSample(filters=36)\n",
    "        \n",
    "        self.dilation1 = DilationLayer(filters=76)\n",
    "        self.dilation2 = DilationLayer(filters=76)\n",
    "        self.dilation3 = DilationLayer(filters=76)\n",
    "        \n",
    "        self.up1 = UpSample(filters=36)\n",
    "        self.up1_concat = tf.keras.layers.Concatenate()\n",
    "        \n",
    "        self.up2 = UpSample(filters=18)\n",
    "        self.up2_concat = tf.keras.layers.Concatenate()\n",
    "        \n",
    "        self.last_concat = tf.keras.layers.Concatenate()\n",
    "        self.last_conv1 = tf.keras.layers.Conv2DTranspose(9, kernel_size=(3, 3), strides=(2,2), padding='same')\n",
    "        self.last_prelu = tf.keras.layers.PReLU()\n",
    "        self.last_layer = tf.keras.layers.Conv2D(2, kernel_size=(3, 3), \n",
    "                                                 padding='same', dilation_rate=(1,1), activation=tf.nn.sigmoid)\n",
    "#         self.up3 = UpSample(filters=2)\n",
    "        \n",
    "        self.beta_road = tf.constant(0.5)\n",
    "        self.beta_car = tf.constant(2.)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        d1 = self.down1(inputs)\n",
    "        d2 = self.down2(d1)\n",
    "        x = self.down3(d2)\n",
    "        x = self.dilation1(x)\n",
    "        x = self.dilation2(x)\n",
    "        x = self.dilation3(x)\n",
    "        x = self.up1(x)\n",
    "        x = self.up1_concat([x, d2])\n",
    "        x = self.up2(x)\n",
    "        x = self.up2_concat([x, d1])\n",
    "        x = self.last_conv1(x)\n",
    "        x = self.last_concat([x, inputs])\n",
    "        x = self.last_layer(x)\n",
    "        return x\n",
    "        \n",
    "    def loss(self, predictions, targets):\n",
    "        \"\"\"road = layer [0], car = layer [1]\"\"\"\n",
    "        \n",
    "        \n",
    "        y = self(inputs)\n",
    "        loss = tf.losses.softmax_cross_entropy(onehot_labels=targets, logits=y)\n",
    "        return loss\n",
    "\n",
    "    def loss_dice_coef(self, y_hat, y):\n",
    "#         y = tf.reshape(y, [-1])\n",
    "#         y_hat = tf.reshape(y_hat, [-1])\n",
    "        \n",
    "        intersection = tf.reduce_sum(y * y_hat)\n",
    "        top = 2 * intersection + 1\n",
    "        bottom = tf.reduce_sum(y) + tf.reduce_sum(y_hat) + 1\n",
    "        return -top/bottom\n",
    "#         return tf.losses.sparse_softmax_cross_entropy(labels=y, logits=y_hat)\n",
    "    \n",
    "    def grad(self, x, y):\n",
    "        with tfe.GradientTape() as tape:\n",
    "            y_hat = self(x)\n",
    "            loss_value = self.loss_dice_coef(y_hat, y)\n",
    "        return tape.gradient(loss_value, self.variables)\n",
    "    \n",
    "    def train(self, x, y, optimizer):\n",
    "        grads = self.grad(x, y)\n",
    "        optimizer.apply_gradients(zip(grads, self.variables),\n",
    "                                  global_step=tf.train.get_or_create_global_step())\n",
    "    \n",
    "    def save(self):\n",
    "        self.save_weights(\"model_weights.h5\")\n",
    "\n",
    "    def load(self):\n",
    "        self.load_weights(\"model_weights.h5\")\n",
    "    \n",
    "model = DilatedCNN()\n",
    "x = tf.convert_to_tensor(images[0:1], dtype=tf.float32)\n",
    "print(x.shape)\n",
    "\n",
    "%time test = model(x)\n",
    "print(test.shape)\n",
    "y_hat = np.array([[1, 0, 1, 1],\n",
    "                  [1, 0, 1, 1],\n",
    "                  [1, 1, 0, 1],\n",
    "                  [1, 1, 0, 1]\n",
    "                 ])\n",
    "\n",
    "y = np.array(    [[1, 0, 1, 0],\n",
    "                  [1, 0, 1, 0],\n",
    "                  [1, 1, 0, 1],\n",
    "                  [1, 1, 0, 1]\n",
    "                 ])\n",
    "\n",
    "out = model.loss_dice_coef(y_hat, y)\n",
    "print(out)\n",
    "\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.load_weights(\"model_weights.h5\")\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# image = images[2]\n",
    "# mask = processed_masks[2]\n",
    "# multi_plot([image, mask[:, :, 0], mask[:, :, 1]])\n",
    "\n",
    "x = tf.constant(images[: 5], dtype=tf.float32)\n",
    "y = tf.constant(processed_masks[:5], dtype=tf.float32)\n",
    "\n",
    "for i in range(200):\n",
    "    model.train(x, y, optimizer)\n",
    "    if i % 10 == 0:\n",
    "        y_hat = model(x)\n",
    "        print(i, model.loss_dice_coef(y_hat, y))\n",
    "\n",
    "print(\"done\")\n",
    "%time y_hat = model(x)\n",
    "index = 2\n",
    "multi_plot([images[index], y_hat[index][:, :, 0], y_hat[index][:, :, 1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%time y_hat = model(x[0:1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.save_weights(\"model_weights.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
